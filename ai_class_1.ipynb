{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0GFAs8auHtdtSAuofiCtx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devv07/AI_Practice/blob/main/ai_class_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#searching (linear and binary search)   linear O(n) it means =8 value 8 time  complicity\n",
        "def greet():\n",
        "  print(\"hello there\")\n",
        "  print(\"Welcome to home\")\n",
        "  print(\"Tea or coffee\")\n",
        "  print(\"please have a seat\")\n",
        "  print('\\n')\n",
        "\n",
        "greet()\n",
        "greet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvyzW6vqXHek",
        "outputId": "62ab6e82-8fa6-4451-c934-80d02f470cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there\n",
            "Welcome to home\n",
            "Tea or coffee\n",
            "please have a seat\n",
            "\n",
            "\n",
            "hello there\n",
            "Welcome to home\n",
            "Tea or coffee\n",
            "please have a seat\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "  print(f'hello there {name}')\n",
        "  print(f'welcome to home {name}')\n",
        "  print(f'tea or coffee {name}')\n",
        "  print(f'Please have a seat {name}')\n",
        "  print('\\n')\n",
        "\n",
        "greet('Hari')\n",
        "greet('sita')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5oYDWxIZ5Cz",
        "outputId": "c393572b-5610-4203-ee07-b294e1c697f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there Hari\n",
            "welcome to home Hari\n",
            "tea or coffee Hari\n",
            "Please have a seat Hari\n",
            "\n",
            "\n",
            "hello there sita\n",
            "welcome to home sita\n",
            "tea or coffee sita\n",
            "Please have a seat sita\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#linear Search    O(n)\n",
        "def linear_search(arr,target):\n",
        "  for i in range(len(arr)):\n",
        "    if arr[i]==target:\n",
        "      return i\n",
        "  return -1\n",
        "\n",
        "result=linear_search([20,30,40,50,60],50)\n",
        "\n",
        "if result==-1:\n",
        "  print(\"Element are not found\")\n",
        "else:\n",
        "  print(f'Element found at index {result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10CcxAIcb3EE",
        "outputId": "2f33d947-2a45-4ba5-e8b9-9f4c98bbbab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element found at index 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[20,30,40,50,60].index(60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW_vaRZUi5C_",
        "outputId": "689aecde-f8b3-48d2-edeb-1cff00c93f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#binary search     O(logn)  eg. 2^4=2,2^16=4   log(n)\n",
        "def binary_search(arr,target):\n",
        "  left=0\n",
        "  right=len(arr)-1\n",
        "  while left<=right:\n",
        "    mid=(left+right)//2   #list indices must be integers or slices, not float if single /\n",
        "\n",
        "    if arr[mid]==target:\n",
        "      return mid     # it only print the index\n",
        "    elif arr[mid]<target:\n",
        "      left=mid+1     # it add the value in left to right side\n",
        "    else:\n",
        "      right=mid-1    # it sub the value from right to left side\n",
        "  else:\n",
        "    return -1        # no return if condition are not found\n",
        "\n",
        "array=[10,20,30,40,50,60]\n",
        "target=50\n",
        "result=binary_search(array,target)\n",
        "if result ==-1:\n",
        "  print(\"Element are not found\")\n",
        "else:\n",
        "  print(f'Element are found {result}')\n",
        "  print(f'Element are {array[3]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wILkDDQ4eA4w",
        "outputId": "c4b01eed-8184-4577-cd4a-d9adcf1404a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element are found 4\n",
            "Element are 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph Searching : Used in map searching, eg. pathao food,foodmandu, etc\n",
        "Types:\n",
        "1. Uninformend/blind Search : Depth-First Search Breath First Search,Uniform Cost Search\n",
        "2. Informed/heuristics Search : Best First Search,Hill Climbing Search, Simulated Annealing, A* search, etc\n",
        "\n",
        "---\n",
        "\n",
        "               A\n",
        "              / \\\n",
        "            B    C\n",
        "          /  \\    \\\n",
        "        D     E----F\n",
        "\n"
      ],
      "metadata": {
        "id": "j-SVPdXCgwlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Depth First Search\n",
        "\n",
        "def dfs_resursive(graph,start,visited=None):\n",
        "  if visited is None:\n",
        "    visited=set()\n",
        "  visited.add(start)\n",
        "  print(start)\n",
        "\n",
        "  for neighbor in graph[start]:\n",
        "    if neighbor not in visited:\n",
        "      dfs_resursive(graph,neighbor,visited)\n",
        "\n",
        "graph={\n",
        "    'A':['B','C'],\n",
        "    'B':['D','E'],\n",
        "    'C':['F'],\n",
        "    'D':[],\n",
        "    'E':['F'],\n",
        "    'F':[]\n",
        "}\n",
        "\n",
        "dfs_resursive(graph,'A')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL6qWuaSgEuw",
        "outputId": "d6f21916-e345-4167-e79e-8a657c09a719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "B\n",
            "D\n",
            "E\n",
            "F\n",
            "C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Breadth First Search(BFS)\n",
        "\n",
        "from collections import deque     #(stack LIFO) , (queue FIFO)  and (deque is a double ended queue)\n",
        "\n",
        "def bfs(graph,start):\n",
        "  visited=set()\n",
        "  queue=deque([start])\n",
        "\n",
        "  while queue:\n",
        "    node=queue.popleft()\n",
        "    if node not in visited:\n",
        "      print(node)\n",
        "      visited.add(node)\n",
        "      queue.extend(neighbor for neighbor in graph[node] if neighbor not in visited)\n",
        "\n",
        "graph={\n",
        "    'A':['B','C'],\n",
        "    'B':['D','E'],\n",
        "    'C':['F'],\n",
        "    'D':[],\n",
        "    'E':['F'],\n",
        "    'F':[]\n",
        "}\n",
        "bfs(graph,'A')"
      ],
      "metadata": {
        "id": "ONryHBq0qtAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976b3e0f-1806-4097-c3d5-4252e4f21875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "B\n",
            "C\n",
            "D\n",
            "E\n",
            "F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#informed Searching(heuristics)\n",
        "# Best first search\n",
        "\n",
        "import heapq\n",
        "def best_first_search(graph,start,goal,heuristics):\n",
        "  visited=set()\n",
        "  priority_queue=[]\n",
        "  heapq.heappush(priority_queue,(heuristics[start],start,[start]))\n",
        "  while priority_queue:\n",
        "    h_cost,current,path=heapq.heappop(priority_queue)\n",
        "    if current in visited:\n",
        "      continue\n",
        "    visited.add(current)\n",
        "    if current==goal:\n",
        "      return path\n",
        "    for neighbor,_ in graph[current]:\n",
        "      if neighbor not in visited:\n",
        "        heapq.heappush(priority_queue,(heuristics[neighbor],neighbor,path+[neighbor]))\n",
        "  print(\"No path found\")\n",
        "  return None\n",
        "\n",
        "graph={\n",
        "    'A':[('B',1),('C',4)],\n",
        "    'B':[('D',5),('E',12)],\n",
        "    'C':[('F',2)],\n",
        "    'D':[('G',3)],\n",
        "    'E':[('G',2)],\n",
        "    'F':[('E',1)],\n",
        "    'G':[]\n",
        "}\n",
        "\n",
        "heuristics={\n",
        "    'A':7,\n",
        "    'B':6,\n",
        "    'C':5,\n",
        "    'D':3,\n",
        "    'E':1,\n",
        "    'F':4,\n",
        "    'G':0\n",
        "}\n",
        "best_first_search(graph,\"A\",\"G\",heuristics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-b7hb-puW9y",
        "outputId": "4dad3a3e-c5c1-4cb7-b430-87fd7bc153cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'C', 'F', 'E', 'G']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A* Search    heapq is a priority queqe it deleted the smallest value\n",
        "import heapq\n",
        "def a_star_search(graph,start,goal,heuristic):\n",
        "  item=[]\n",
        "  heapq.heappush(item,(0+heuristic[start],0,start,[start]))\n",
        "  visited=set()\n",
        "\n",
        "  while item:\n",
        "    f_cost,g_cost,current,path=heapq.heappop(item)\n",
        "    if current in visited:\n",
        "      continue\n",
        "    visited.add(current)\n",
        "\n",
        "    if current==goal:\n",
        "      print(\"Total Cost: \",g_cost)\n",
        "      print('Path is: ')\n",
        "      return path\n",
        "\n",
        "    for neighbor,cost in graph[current]:\n",
        "      if neighbor not in visited:\n",
        "        new_g=g_cost+cost\n",
        "        new_f=new_g+heuristic[neighbor]\n",
        "        heapq.heappush(item,(new_f,new_g,neighbor,path+[neighbor]))\n",
        "  print(\"No Path found\")\n",
        "  return None\n",
        "graph={\n",
        "    'A':[('B',1),('C',4)],\n",
        "    'B':[('D',5),('E',12)],\n",
        "    'C':[('F',2)],\n",
        "    'D':[('G',3)],\n",
        "    'E':[('G',2)],\n",
        "    'F':[('E',1)],\n",
        "    'G':[]\n",
        "}\n",
        "\n",
        "heuristic={\n",
        "    'A':7,\n",
        "    'B':6,\n",
        "    'C':5,\n",
        "    'D':3,\n",
        "    'E':1,\n",
        "    'F':4,\n",
        "    'G':0\n",
        "}\n",
        "\n",
        "a_star_search(graph,'A','G',heuristic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK_ClMplwe8J",
        "outputId": "6372f190-9f68-4cf8-8c4c-ac279b607e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Cost:  9\n",
            "Path is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'B', 'D', 'G']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning is the subset of AI, where the machine should learn from expreince. As name suggests, the machine should keep learning from data.\n",
        "Types of ML\n",
        " 1. Supervised ML (used in labelled datasets)\n",
        "\n",
        "    a. Regression -> Predicting a value with labelled data is called Regression. eg 20 degree temp for tommorrow, 90 mark of student, etc.\n",
        "\n",
        "    Algorithms used : Linear regression, non-linear regression, polynomial regression\n",
        "\n",
        "   b. Classification : Predcting a class/category with labelled data is called classfication. eg, higrhor low, rainy mild or foggy etc,\n",
        "\n",
        "   Algoritms used: Decicion Tree, KNN,SVM,Nive Bayes,Logistic regressin etc.\n",
        "   \n",
        "2. Unsupervised ML (used in unlabelled datasets)\n",
        "\n",
        "   a. Clustering\n",
        "   \n",
        "   b. Association"
      ],
      "metadata": {
        "id": "bDtlonAY2DQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries and tools for machine learning\n",
        "\n",
        "1. Pandas -> Data analysis library\n",
        "2. Scikit-learn -> Model building Library\n",
        "3. joblib/pickle -> to save ML model\n",
        "4. matplotlib -- > Visualization library/matrix plotting library"
      ],
      "metadata": {
        "id": "Sa_h3GLf3d6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/sample_data/music.csv')\n",
        "data\n",
        "\n",
        "#Exploratory Data Analysis(EDA)\n",
        "data.shape    # number of row and colunm\n",
        "data.size  # toatal size of data\n",
        "data.describe()   # give the ststistical analysis\n",
        "data.head()  # gove the top 5 rows\n",
        "data.tail(4) # give the last 5 rows\n",
        "data.sample(4)  # gives the random samples by shuffling\n",
        "data.info() # give the information about data\n",
        "data.dtypes # give the data type of each column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Wq6uTwaJ0CIX",
        "outputId": "f09af2ee-cfd4-4021-8e1c-b165e48df466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18 entries, 0 to 17\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   age     18 non-null     int64 \n",
            " 1   gender  18 non-null     int64 \n",
            " 2   genre   18 non-null     object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 564.0+ bytes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age        int64\n",
              "gender     int64\n",
              "genre     object\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "# Just to predict\n",
        "import pandas as pd\n",
        "data=pd.read_csv('/content/sample_data/music.csv')\n",
        "x=data[['age','gender']]\n",
        "y=data['genre']\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model=DecisionTreeClassifier()\n",
        "model.fit(x.values,y.values)\n",
        "model.predict([[22,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUETm7Pd2Xh1",
        "outputId": "039a3702-a2b8-4d84-e721-0a5f8aee836f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HipHop'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "# To predict and check the accuracy as well\n",
        "import pandas as pd\n",
        "data=pd.read_csv('/content/sample_data/music.csv')\n",
        "x=data[['age','gender']]\n",
        "y=data['genre']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model=DecisionTreeClassifier()\n",
        "model.fit(x_train.values,y_train.values)\n",
        "prediction=model.predict(x_test.values)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(prediction,x_train)\n",
        "model.predict([[22,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "M2_D85FICIDX",
        "outputId": "b7316c14-a47e-41c5-efbe-ca0e0bf99a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [4, 14]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-323864912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 14]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "shV8hXZG0BXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "import pandas as pd\n",
        "data=pd.read_csv('/content/sample_data/music.csv')\n",
        "x=data[['age','gender']]\n",
        "y=data['genre']\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model=KNeighborsClassifier()\n",
        "model.fit(x.values,y.values)\n",
        "model.predict([[22,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvD-chLc6R2A",
        "outputId": "fc426200-ffe4-4b09-d45a-4642599af2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HipHop'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "import pandas as pd\n",
        "data=pd.read_csv('/content/sample_data/music.csv')\n",
        "x=data[['age','gender']]\n",
        "y=data['genre']\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression(max_iter=800)\n",
        "model.fit(x.values,y.values)\n",
        "model.predict([[22,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXxnhiVC6ssR",
        "outputId": "dbafcbe7-1ad3-48c4-f28d-83706f4d19a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HipHop'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Navis Bayess\n",
        "import pandas as pd\n",
        "data=pd.read_csv('/content/sample_data/music.csv')\n",
        "x=data[['age','gender']]\n",
        "y=data['genre']\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model=GaussianNB()\n",
        "model.fit(x.values,y.values)\n",
        "model.predict([[22,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqWRWox77SW-",
        "outputId": "b86ff94f-dacb-4ea6-b9d3-9273d67e85c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HipHop'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support vector Machaine\n",
        "import pandas as pd\n",
        "data=pd.read_csv('/content/sample_data/music.csv')\n",
        "x=data[['age','gender']]\n",
        "y=data['genre']\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "model=SVC()\n",
        "model.fit(x.values,y.values)\n",
        "model.predict([[22,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_KX2pga7STk",
        "outputId": "05fc6091-bb4c-4d6d-ae00-fd21c9d4618a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HipHop'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "framworkd for implementing Deep Learning\n",
        "Tensorflow  -> By google\n",
        "keras -> high level API of tensorflow\n",
        "PyTorch  -> by mete, support the GPU component CUDA\n",
        "CNTk  Microsoft\n"
      ],
      "metadata": {
        "id": "EOfLL2IB7jiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fashion-mnist classification using deoop learning\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data=keras.datasets.fashion_mnist\n",
        "(train_images,train_lables),(test_images,test_labels)=data.load_data()"
      ],
      "metadata": {
        "id": "nnqyP-5G7bOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat=[\n",
        "    [0,255],\n",
        "    [150,200]\n",
        "]\n",
        "\n",
        "plt.imshow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "ruJLdr98_oqD",
        "outputId": "59ed93d6-2f93-4cfc-e1e5-86daa12d09b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.imshow(X: 'ArrayLike | PIL.Image.Image', cmap: 'str | Colormap | None' = None, norm: 'str | Normalize | None' = None, *, aspect: \"Literal['equal', 'auto'] | float | None\" = None, interpolation: 'str | None' = None, alpha: 'float | ArrayLike | None' = None, vmin: 'float | None' = None, vmax: 'float | None' = None, colorizer: 'Colorizer | None' = None, origin: \"Literal['upper', 'lower'] | None\" = None, extent: 'tuple[float, float, float, float] | None' = None, interpolation_stage: \"Literal['data', 'rgba', 'auto'] | None\" = None, filternorm: 'bool' = True, filterrad: 'float' = 4.0, resample: 'bool | None' = None, url: 'str | None' = None, data=None, **kwargs) -> 'AxesImage'>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.imshow</b><br/>def imshow(X: ArrayLike | PIL.Image.Image, cmap: str | Colormap | None=None, norm: str | Normalize | None=None, *, aspect: Literal[&#x27;equal&#x27;, &#x27;auto&#x27;] | float | None=None, interpolation: str | None=None, alpha: float | ArrayLike | None=None, vmin: float | None=None, vmax: float | None=None, colorizer: Colorizer | None=None, origin: Literal[&#x27;upper&#x27;, &#x27;lower&#x27;] | None=None, extent: tuple[float, float, float, float] | None=None, interpolation_stage: Literal[&#x27;data&#x27;, &#x27;rgba&#x27;, &#x27;auto&#x27;] | None=None, filternorm: bool=True, filterrad: float=4.0, resample: bool | None=None, url: str | None=None, data=None, **kwargs) -&gt; AxesImage</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py</a>Display data as an image, i.e., on a 2D regular raster.\n",
              "\n",
              "The input may either be actual RGB(A) data, or 2D scalar data, which\n",
              "will be rendered as a pseudocolor image. For displaying a grayscale\n",
              "image, set up the colormapping using the parameters\n",
              "``cmap=&#x27;gray&#x27;, vmin=0, vmax=255``.\n",
              "\n",
              "The number of pixels used to render an image is set by the Axes size\n",
              "and the figure *dpi*. This can lead to aliasing artifacts when\n",
              "the image is resampled, because the displayed image size will usually\n",
              "not match the size of *X* (see\n",
              ":doc:`/gallery/images_contours_and_fields/image_antialiasing`).\n",
              "The resampling can be controlled via the *interpolation* parameter\n",
              "and/or :rc:`image.interpolation`.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "X : array-like or PIL image\n",
              "    The image data. Supported array shapes are:\n",
              "\n",
              "    - (M, N): an image with scalar data. The values are mapped to\n",
              "      colors using normalization and a colormap. See parameters *norm*,\n",
              "      *cmap*, *vmin*, *vmax*.\n",
              "    - (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
              "    - (M, N, 4): an image with RGBA values (0-1 float or 0-255 int),\n",
              "      i.e. including transparency.\n",
              "\n",
              "    The first two dimensions (M, N) define the rows and columns of\n",
              "    the image.\n",
              "\n",
              "    Out-of-range RGB(A) values are clipped.\n",
              "\n",
              "cmap : str or `~matplotlib.colors.Colormap`, default: :rc:`image.cmap`\n",
              "    The Colormap instance or registered colormap name used to map scalar data\n",
              "    to colors.\n",
              "\n",
              "    This parameter is ignored if *X* is RGB(A).\n",
              "\n",
              "norm : str or `~matplotlib.colors.Normalize`, optional\n",
              "    The normalization method used to scale scalar data to the [0, 1] range\n",
              "    before mapping to colors using *cmap*. By default, a linear scaling is\n",
              "    used, mapping the lowest value to 0 and the highest to 1.\n",
              "\n",
              "    If given, this can be one of the following:\n",
              "\n",
              "    - An instance of `.Normalize` or one of its subclasses\n",
              "      (see :ref:`colormapnorms`).\n",
              "    - A scale name, i.e. one of &quot;linear&quot;, &quot;log&quot;, &quot;symlog&quot;, &quot;logit&quot;, etc.  For a\n",
              "      list of available scales, call `matplotlib.scale.get_scale_names()`.\n",
              "      In that case, a suitable `.Normalize` subclass is dynamically generated\n",
              "      and instantiated.\n",
              "\n",
              "    This parameter is ignored if *X* is RGB(A).\n",
              "\n",
              "vmin, vmax : float, optional\n",
              "    When using scalar data and no explicit *norm*, *vmin* and *vmax* define\n",
              "    the data range that the colormap covers. By default, the colormap covers\n",
              "    the complete value range of the supplied data. It is an error to use\n",
              "    *vmin*/*vmax* when a *norm* instance is given (but using a `str` *norm*\n",
              "    name together with *vmin*/*vmax* is acceptable).\n",
              "\n",
              "    This parameter is ignored if *X* is RGB(A).\n",
              "\n",
              "colorizer : `~matplotlib.colorizer.Colorizer` or None, default: None\n",
              "    The Colorizer object used to map color to data. If None, a Colorizer\n",
              "    object is created from a *norm* and *cmap*.\n",
              "\n",
              "    This parameter is ignored if *X* is RGB(A).\n",
              "\n",
              "aspect : {&#x27;equal&#x27;, &#x27;auto&#x27;} or float or None, default: None\n",
              "    The aspect ratio of the Axes.  This parameter is particularly\n",
              "    relevant for images since it determines whether data pixels are\n",
              "    square.\n",
              "\n",
              "    This parameter is a shortcut for explicitly calling\n",
              "    `.Axes.set_aspect`. See there for further details.\n",
              "\n",
              "    - &#x27;equal&#x27;: Ensures an aspect ratio of 1. Pixels will be square\n",
              "      (unless pixel sizes are explicitly made non-square in data\n",
              "      coordinates using *extent*).\n",
              "    - &#x27;auto&#x27;: The Axes is kept fixed and the aspect is adjusted so\n",
              "      that the data fit in the Axes. In general, this will result in\n",
              "      non-square pixels.\n",
              "\n",
              "    Normally, None (the default) means to use :rc:`image.aspect`.  However, if\n",
              "    the image uses a transform that does not contain the axes data transform,\n",
              "    then None means to not modify the axes aspect at all (in that case, directly\n",
              "    call `.Axes.set_aspect` if desired).\n",
              "\n",
              "interpolation : str, default: :rc:`image.interpolation`\n",
              "    The interpolation method used.\n",
              "\n",
              "    Supported values are &#x27;none&#x27;, &#x27;auto&#x27;, &#x27;nearest&#x27;, &#x27;bilinear&#x27;,\n",
              "    &#x27;bicubic&#x27;, &#x27;spline16&#x27;, &#x27;spline36&#x27;, &#x27;hanning&#x27;, &#x27;hamming&#x27;, &#x27;hermite&#x27;,\n",
              "    &#x27;kaiser&#x27;, &#x27;quadric&#x27;, &#x27;catrom&#x27;, &#x27;gaussian&#x27;, &#x27;bessel&#x27;, &#x27;mitchell&#x27;,\n",
              "    &#x27;sinc&#x27;, &#x27;lanczos&#x27;, &#x27;blackman&#x27;.\n",
              "\n",
              "    The data *X* is resampled to the pixel size of the image on the\n",
              "    figure canvas, using the interpolation method to either up- or\n",
              "    downsample the data.\n",
              "\n",
              "    If *interpolation* is &#x27;none&#x27;, then for the ps, pdf, and svg\n",
              "    backends no down- or upsampling occurs, and the image data is\n",
              "    passed to the backend as a native image.  Note that different ps,\n",
              "    pdf, and svg viewers may display these raw pixels differently. On\n",
              "    other backends, &#x27;none&#x27; is the same as &#x27;nearest&#x27;.\n",
              "\n",
              "    If *interpolation* is the default &#x27;auto&#x27;, then &#x27;nearest&#x27;\n",
              "    interpolation is used if the image is upsampled by more than a\n",
              "    factor of three (i.e. the number of display pixels is at least\n",
              "    three times the size of the data array).  If the upsampling rate is\n",
              "    smaller than 3, or the image is downsampled, then &#x27;hanning&#x27;\n",
              "    interpolation is used to act as an anti-aliasing filter, unless the\n",
              "    image happens to be upsampled by exactly a factor of two or one.\n",
              "\n",
              "    See\n",
              "    :doc:`/gallery/images_contours_and_fields/interpolation_methods`\n",
              "    for an overview of the supported interpolation methods, and\n",
              "    :doc:`/gallery/images_contours_and_fields/image_antialiasing` for\n",
              "    a discussion of image antialiasing.\n",
              "\n",
              "    Some interpolation methods require an additional radius parameter,\n",
              "    which can be set by *filterrad*. Additionally, the antigrain image\n",
              "    resize filter is controlled by the parameter *filternorm*.\n",
              "\n",
              "interpolation_stage : {&#x27;auto&#x27;, &#x27;data&#x27;, &#x27;rgba&#x27;}, default: &#x27;auto&#x27;\n",
              "    Supported values:\n",
              "\n",
              "    - &#x27;data&#x27;: Interpolation is carried out on the data provided by the user\n",
              "      This is useful if interpolating between pixels during upsampling.\n",
              "    - &#x27;rgba&#x27;: The interpolation is carried out in RGBA-space after the\n",
              "      color-mapping has been applied. This is useful if downsampling and\n",
              "      combining pixels visually.\n",
              "    - &#x27;auto&#x27;: Select a suitable interpolation stage automatically. This uses\n",
              "      &#x27;rgba&#x27; when downsampling, or upsampling at a rate less than 3, and\n",
              "      &#x27;data&#x27; when upsampling at a higher rate.\n",
              "\n",
              "    See :doc:`/gallery/images_contours_and_fields/image_antialiasing` for\n",
              "    a discussion of image antialiasing.\n",
              "\n",
              "alpha : float or array-like, optional\n",
              "    The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
              "    If *alpha* is an array, the alpha blending values are applied pixel\n",
              "    by pixel, and *alpha* must have the same shape as *X*.\n",
              "\n",
              "origin : {&#x27;upper&#x27;, &#x27;lower&#x27;}, default: :rc:`image.origin`\n",
              "    Place the [0, 0] index of the array in the upper left or lower\n",
              "    left corner of the Axes. The convention (the default) &#x27;upper&#x27; is\n",
              "    typically used for matrices and images.\n",
              "\n",
              "    Note that the vertical axis points upward for &#x27;lower&#x27;\n",
              "    but downward for &#x27;upper&#x27;.\n",
              "\n",
              "    See the :ref:`imshow_extent` tutorial for\n",
              "    examples and a more detailed description.\n",
              "\n",
              "extent : floats (left, right, bottom, top), optional\n",
              "    The bounding box in data coordinates that the image will fill.\n",
              "    These values may be unitful and match the units of the Axes.\n",
              "    The image is stretched individually along x and y to fill the box.\n",
              "\n",
              "    The default extent is determined by the following conditions.\n",
              "    Pixels have unit size in data coordinates. Their centers are on\n",
              "    integer coordinates, and their center coordinates range from 0 to\n",
              "    columns-1 horizontally and from 0 to rows-1 vertically.\n",
              "\n",
              "    Note that the direction of the vertical axis and thus the default\n",
              "    values for top and bottom depend on *origin*:\n",
              "\n",
              "    - For ``origin == &#x27;upper&#x27;`` the default is\n",
              "      ``(-0.5, numcols-0.5, numrows-0.5, -0.5)``.\n",
              "    - For ``origin == &#x27;lower&#x27;`` the default is\n",
              "      ``(-0.5, numcols-0.5, -0.5, numrows-0.5)``.\n",
              "\n",
              "    See the :ref:`imshow_extent` tutorial for\n",
              "    examples and a more detailed description.\n",
              "\n",
              "filternorm : bool, default: True\n",
              "    A parameter for the antigrain image resize filter (see the\n",
              "    antigrain documentation).  If *filternorm* is set, the filter\n",
              "    normalizes integer values and corrects the rounding errors. It\n",
              "    doesn&#x27;t do anything with the source floating point values, it\n",
              "    corrects only integers according to the rule of 1.0 which means\n",
              "    that any sum of pixel weights must be equal to 1.0.  So, the\n",
              "    filter function must produce a graph of the proper shape.\n",
              "\n",
              "filterrad : float &gt; 0, default: 4.0\n",
              "    The filter radius for filters that have a radius parameter, i.e.\n",
              "    when interpolation is one of: &#x27;sinc&#x27;, &#x27;lanczos&#x27; or &#x27;blackman&#x27;.\n",
              "\n",
              "resample : bool, default: :rc:`image.resample`\n",
              "    When *True*, use a full resampling method.  When *False*, only\n",
              "    resample when the output image is larger than the input image.\n",
              "\n",
              "url : str, optional\n",
              "    Set the url of the created `.AxesImage`. See `.Artist.set_url`.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "`~matplotlib.image.AxesImage`\n",
              "\n",
              "Other Parameters\n",
              "----------------\n",
              "data : indexable object, optional\n",
              "    If given, all parameters also accept a string ``s``, which is\n",
              "    interpreted as ``data[s]`` if ``s`` is a key in ``data``.\n",
              "\n",
              "**kwargs : `~matplotlib.artist.Artist` properties\n",
              "    These parameters are passed on to the constructor of the\n",
              "    `.AxesImage` artist.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "matshow : Plot a matrix or an array as an image.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "\n",
              ".. note::\n",
              "\n",
              "    This is the :ref:`pyplot wrapper &lt;pyplot_interface&gt;` for `.axes.Axes.imshow`.\n",
              "\n",
              "Unless *extent* is used, pixel centers will be located at integer\n",
              "coordinates. In other words: the origin will coincide with the center\n",
              "of pixel (0, 0).\n",
              "\n",
              "There are two common representations for RGB images with an alpha\n",
              "channel:\n",
              "\n",
              "-   Straight (unassociated) alpha: R, G, and B channels represent the\n",
              "    color of the pixel, disregarding its opacity.\n",
              "-   Premultiplied (associated) alpha: R, G, and B channels represent\n",
              "    the color of the pixel, adjusted for its opacity by multiplication.\n",
              "\n",
              "`~matplotlib.pyplot.imshow` expects RGB images adopting the straight\n",
              "(unassociated) alpha representation.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 3570);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_images[123])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "gWlkRrAXAQ5F",
        "outputId": "c2944b01-427b-4b69-e02e-a32743b7a04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7831718622d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['T-Shirt/top','Trouser','']"
      ],
      "metadata": {
        "id": "6nbRqnH9CuQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential(\n",
        "    keras.layers.Flatten(input_shape=(28,28))\n",
        "    keras.layers.Deense(128,activation='relu')\n",
        "    keras.layers.Dense(10,activation='softmax')\n",
        ")"
      ],
      "metadata": {
        "id": "di3O0yLcBcZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='admin')"
      ],
      "metadata": {
        "id": "twCDAZnfCIE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class_names[np.argmax(predication[0])]"
      ],
      "metadata": {
        "id": "Y4slcqreDjEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f3M-iFpXDYd7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}